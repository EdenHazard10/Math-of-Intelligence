# Logistic Regression with Newton's Method
An implementation of the Second Order Newton optimization method, demonstrated with logistic regression.

## Introduction
This is a response to Siraj Raval's [Coding Challenge](https://github.com/llSourcell/Second_Order_Optimization_Newtons_Method) as part of The Math of Intelligence course.
In this notebook, we will be building a logistic regression model using Newton's 2nd Order Optimization Method with numpy. Batch gradient ascent is also demonstrated, as another commmonly used optimization method. 

We will be using the Kaggle [Breast Cancer Wisconsin](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) Data Set to classify if a tumour is malignant or benign, based on 30 features, such as the mean radius.

## Requirements
* python3
* numpy
* pandas
* matplotlib

## Usage
Run `jupyter notebook` in your Python 3 environment


## References
1. [Logistic Regression Newton's Method](https://github.com/llSourcell/logistic_regression_newtons_method) by Siraj Raval  
2. [CS229 - Logistic Regression](http://cs229.stanford.edu/notes/cs229-notes1.pdf) by Andrew Ng