{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Organizing Feature Maps\n",
    "The goal of this notebook is to build and understand the properties of Kohonen Self-Organizing Feature Maps, an unsupervised learning technique for representing high dimensional data in much lower dimensional spaces, while maintaining the topological relationships within the training set.\n",
    "\n",
    "We will begin first by building a model that can map colors in RGB to a 2 dimensional representation. Next, we will take the same model and apply it to a more advanced problem of learning from the MNIST dataset.\n",
    "\n",
    "![](http://www.ai-junkie.com/ann/som/images/Figure1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SOM is a lattice made up of n by n nodes. From an initial random distribution of weights, the weights are adjusted over training to classify the input data more effectively, until it converges to a steady representation of different zones (equivalent to classes). Given an input data, the SOM can classify based as nodes in zone with similar weight vectors will be simulated.\n",
    "\n",
    "## Learning Algorithm\n",
    "  \n",
    "\n",
    "For N Iterations:\n",
    "1. Initialise weights of each node in lattice randomly\n",
    "2. Select a vector from training data to compare with the lattice.\n",
    "3. Choose Best Matching Unit (BMU) from lattice, by computing the most similar node to vector.\n",
    "4. Compute the radius of BMU's neighbourhood. This value decreases each time-step.\n",
    "5. Adjust each node within the BMU's neighbourhood to make them more similar to the input vector. Closer nodes are adusted more.\n",
    "6. Repeat Step 2 to 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Network\n",
    "The following equations are implemented in the SOM code. For detailed explanation, check out http://www.ai-junkie.com/ann/som/som3.html.\n",
    "\n",
    "### Neighbourhood Radius \n",
    "![](http://www.ai-junkie.com/ann/som/images/equation2.gif)\n",
    "\n",
    "### Weight Adjustment for Nodes in BMU's Neighbourhood\n",
    "![](http://www.ai-junkie.com/ann/som/images/equation5.gif)\n",
    "\n",
    "### Theta - amount of influence distance has on learning\n",
    "![](http://www.ai-junkie.com/ann/som/images/equation6.gif)\n",
    "\n",
    "### Decaying Learning Rate\n",
    "![](http://www.ai-junkie.com/ann/som/images/equation3.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SOM:\n",
    "    def __init__(self, x_size, y_size, dimen, num_iter, t_step):\n",
    "        # init weights to 0 < w < 256\n",
    "        self.weights = np.random.randint(256, size=(x_size, y_size, dimen))\\\n",
    "                            .astype('float64')\n",
    "        self.num_iter = num_iter\n",
    "        self.map_radius = max(self.weights.shape)/2 # sigma_0\n",
    "        self.t_const = self.num_iter/math.log(self.map_radius) # lambda\n",
    "        self.t_step = t_step\n",
    "        \n",
    "    def get_bmu(self, vector):\n",
    "        # calculate euclidean dist btw weight matrix and vector\n",
    "        distance = np.sum((self.weights - vector) ** 2, 2)\n",
    "        min_idx = distance.argmin()\n",
    "        return np.unravel_index(min_idx, distance.shape)\n",
    "        \n",
    "    def get_bmu_dist(self, vector):\n",
    "        # initialize array where values are its index\n",
    "        x, y, rgb = self.weights.shape\n",
    "        xi = np.arange(x).reshape(x, 1).repeat(y, 1)\n",
    "        yi = np.arange(y).reshape(1, y).repeat(x, 0)\n",
    "        # returns matrix of distance of each index in 2D from BMU\n",
    "        return np.sum((np.dstack((xi, yi)) - np.array(self.get_bmu(vector))) ** 2, 2)\n",
    "\n",
    "    def get_nbhood_radius(self, iter_count):\n",
    "        return self.map_radius * np.exp(-iter_count/self.t_const)\n",
    "        \n",
    "    def teach_row(self, vector, i):\n",
    "        nbhood_radius = self.get_nbhood_radius(i)\n",
    "        bmu_dist = self.get_bmu_dist(vector).astype('float64')\n",
    "        \n",
    "        # exponential decaying learning rate\n",
    "        lr = 0.1 * np.exp(-i/self.num_iter) \n",
    "        \n",
    "        # influence\n",
    "        theta = np.exp(-(bmu_dist)/ (2 * nbhood_radius ** 2))\n",
    "        return np.expand_dims(theta, 2) * (vector - self.weights)\n",
    "        \n",
    "    def teach(self, t_set):\n",
    "        for i in range(self.num_iter):\n",
    "            if i % 10 == 0:\n",
    "                print(\"Training Iteration: \", i)\n",
    "            for j in range(len(t_set)):\n",
    "                self.weights += self.teach_row(t_set[j], i)\n",
    "        \n",
    "    def show(self):\n",
    "        im = Image.fromarray(self.weights.astype('uint8'), mode='RGB')\n",
    "        im.format = 'JPG'\n",
    "        im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration:  0\n",
      "Training Iteration:  10\n",
      "Training Iteration:  20\n",
      "Training Iteration:  30\n",
      "Training Iteration:  40\n",
      "Training Iteration:  50\n",
      "Training Iteration:  60\n",
      "Training Iteration:  70\n",
      "Training Iteration:  80\n",
      "Training Iteration:  90\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "map_w = 200\n",
    "map_h = 200\n",
    "data_dimens = 3\n",
    "epochs = 100\n",
    "t_step = 1\n",
    "\n",
    "# Initialize a random RGB training set \n",
    "training_set = np.random.randint(256, size=(15, 3))\n",
    "\n",
    "# Defining Map\n",
    "s = SOM(map_w, map_h, data_dimens, epochs, t_step)\n",
    "\n",
    "# Start Training\n",
    "s.teach(training_set)\n",
    "\n",
    "# Display Result\n",
    "s.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you manage to run the code successfully, you will be able to see an image like this ðŸ˜€\n",
    "\n",
    "![](color_trained.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on MNIST Dataset\n",
    "\n",
    "Here, we will take the network we defined earlier to train it on the MNIST dataset. Given a randomized training data of images from 0 to 9, we expect the Self Organizing Feature Map to be able to learn and cluster the feature vectors. By visualizing the final weights, we expect to see similar digits grouped together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using first 10000 images for training\n",
    "train_data = mnist.train.images[:10000,:]\n",
    "\n",
    "# Converting normalized data to values between 0 and 256\n",
    "train_data = train_data * 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration:  0\n",
      "Training Iteration:  10\n",
      "Training Iteration:  20\n",
      "Training Iteration:  30\n",
      "Training Iteration:  40\n",
      "Training Iteration:  50\n",
      "Training Iteration:  60\n",
      "Training Iteration:  70\n",
      "Training Iteration:  80\n",
      "Training Iteration:  90\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "map_w = 20\n",
    "map_h = 20\n",
    "data_dimens = 784\n",
    "epochs = 100\n",
    "t_step = 1\n",
    "\n",
    "# Defining Map\n",
    "mnist_map = SOM(map_w, map_h, data_dimens, epochs, t_step)\n",
    "\n",
    "# Start Training\n",
    "mnist_map.teach(X * 256)\n",
    "\n",
    "# Converting 3D SOM to 2D image\n",
    "map_matrix = np.zeros((560,560))\n",
    "for i in range(map_w):\n",
    "    for j in range(map_h):\n",
    "        map_matrix[i*28:i*28+28, j*28:((j*28)+28)] = mnist_map.weights[i][j].reshape((28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Showing Image\n",
    "map_img = Image.fromarray(im.astype('uint8'))\n",
    "map_img.format = 'JPG'\n",
    "map_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you manage to run the code successfully, you will be able to see an image like this ðŸ˜€\n",
    "\n",
    "![](mnist_trained.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
